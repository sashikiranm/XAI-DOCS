{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Arya XAI (Explainable-AI) About Arya-XAI on Image Classification At Arya.ai, we recently released a new framework - \u2018Arya-XAI\u2019 to simplify DLOps in production. Arya-XAI(short for Arya-Explainable AI) enhances the credibility of the predictions of your DL model by generating new and simple explanations (pertaining to the generation of these predictions) in real time as required by various stakeholders. This is the tutorial-first mode of operation for Arya-xAI and it also illustrates the capabilities of the framework. Current approaches to Explainable AI and their challenges Current approaches to explain black-box DL models are heavily reliant on specific data types and network components, both of which severely limit their applicability to a diverse range of use-cases and novel network architectures. This poses challenges to understand or explain true-to-model functioning(that takes into account the internal design of the model). However, models like SHAP, LIME, Integrated Gradients etc. use a permute-and-predict approach to explain the model functioning. While the approaches do offer approximate explanations of how a DL model works on the input to ultimately yield the output, unfortunately these are understandable only by an AI expert. Unlike the existing models such as SHAP and LIME which do not take the internal structure of a network into account to explain its working, the Arya-XAI framework decodes explanations by computing weightage of each feature together with the node-level weightages for a given neural network architecture, referred to as true-to-model feature and node-level weightages respectively. The framework not only improves reliability on DL models substantially, but also offers easy-to-understand reasons behind the outcome.","title":"Home"},{"location":"#welcome-to-arya-xai-explainable-ai","text":"","title":"Welcome to Arya XAI (Explainable-AI)"},{"location":"#about-arya-xai-on-image-classification","text":"At Arya.ai, we recently released a new framework - \u2018Arya-XAI\u2019 to simplify DLOps in production. Arya-XAI(short for Arya-Explainable AI) enhances the credibility of the predictions of your DL model by generating new and simple explanations (pertaining to the generation of these predictions) in real time as required by various stakeholders. This is the tutorial-first mode of operation for Arya-xAI and it also illustrates the capabilities of the framework.","title":"About Arya-XAI on Image Classification"},{"location":"#current-approaches-to-explainable-ai-and-their-challenges","text":"Current approaches to explain black-box DL models are heavily reliant on specific data types and network components, both of which severely limit their applicability to a diverse range of use-cases and novel network architectures. This poses challenges to understand or explain true-to-model functioning(that takes into account the internal design of the model). However, models like SHAP, LIME, Integrated Gradients etc. use a permute-and-predict approach to explain the model functioning. While the approaches do offer approximate explanations of how a DL model works on the input to ultimately yield the output, unfortunately these are understandable only by an AI expert. Unlike the existing models such as SHAP and LIME which do not take the internal structure of a network into account to explain its working, the Arya-XAI framework decodes explanations by computing weightage of each feature together with the node-level weightages for a given neural network architecture, referred to as true-to-model feature and node-level weightages respectively. The framework not only improves reliability on DL models substantially, but also offers easy-to-understand reasons behind the outcome.","title":"Current approaches to Explainable AI and their challenges"},{"location":"Layer_types/","text":"Layer Types Every neural network consists of multiple layers. Each layer has a variation of the following basic operation: y = \u03a6(Wx + b) where, \u03a6 = activation function \u200bW = weight matrix of the layer \u200bb = bias \u200bx = input \u200by = output Different activation layers perform a range of mathematical functions and are named as follows: Dense layer Convolution layer Pooling layer Recurrent layer (LSTM - Long Short Term Memory networks)","title":"Layer Types"},{"location":"Layer_types/#layer-types","text":"Every neural network consists of multiple layers. Each layer has a variation of the following basic operation: y = \u03a6(Wx + b) where, \u03a6 = activation function \u200bW = weight matrix of the layer \u200bb = bias \u200bx = input \u200by = output Different activation layers perform a range of mathematical functions and are named as follows: Dense layer Convolution layer Pooling layer Recurrent layer (LSTM - Long Short Term Memory networks)","title":"Layer Types"},{"location":"Output/","text":"DEFAULT MODE OUTPUT CONTRASTIVE MODE OUTPUT \u200b (Reference : BLUE - negative contrast , GREEN - positive contrast)","title":"Output"},{"location":"Output/#default-mode-output","text":"","title":"DEFAULT MODE OUTPUT"},{"location":"Output/#contrastive-mode-output","text":"\u200b (Reference : BLUE - negative contrast , GREEN - positive contrast)","title":"CONTRASTIVE MODE OUTPUT"},{"location":"algo/","text":"How does Arya-xAI work? Arya XAI currently has two modes of operation known as default and contrastive mode which are demonstrated through the following use-cases respectively: Network Analysis: In this mode, there is a single,positive significance value that is propagated in proportion to the contribution of each unit. This can be used to prune the underutilized parts of the network and modify the saturated ones. This is also helpful in reducing or enhancing the input features. Decision Analysis: In this mode, there are dual significance values which can be either negative or positive depending on the relative contribution of any unit to the decision. This is helpful in providing explanations regarding the corresponding input features that are positively/ negatively affecting the decision . The procedure for significance/relevance calculation is as follows: From the model weights and architecture construct a graph with output nodes as roots and input nodes as the leaves. The propagation starts at root and proceeds in breadth-first manner to avoid re-processing of any node. The propagation completes when all the leaves(input nodes) have been assigned relevance. For the default mode, any loss of relevance during propagation is due to network bias. However, network bias is ignored for relevance computation in the contrastive mode. The relevance of a single sample represents local importance. For global importance, the relevance of each feature can be aggregated after normalization on the sample level. IMPACT ON PRUNING AND MODEL RESULT ASSESSMENT For model pruning, current explainable approaches offer limited evidence on node/layer level importance in final prediction. The limits range from type of data to network architecture. Arya-XAI uses a unique approach to figure out the importance of each node/layer on the final prediction. This allows a much deeper explainability of the complex black box models for data scientists/researchers, allowing them to gauge which features have the most impact on the model decision. Explanations can be generated at a local level as well as a global level. Global level explanations can be used to study the overall model trend, data usage and identify possible improvements. Local level explanations are important for granular control over data usage and unit level performance of the network. Local level explanations not only help in analyzing model outputs for individual samples, they also help in establishing internal trends in any feature with respect to the decision. This facilitates in building feature-level decision boundaries and flag any adverse predictions.","title":"Algorithm"},{"location":"algo/#how-does-arya-xai-work","text":"Arya XAI currently has two modes of operation known as default and contrastive mode which are demonstrated through the following use-cases respectively: Network Analysis: In this mode, there is a single,positive significance value that is propagated in proportion to the contribution of each unit. This can be used to prune the underutilized parts of the network and modify the saturated ones. This is also helpful in reducing or enhancing the input features. Decision Analysis: In this mode, there are dual significance values which can be either negative or positive depending on the relative contribution of any unit to the decision. This is helpful in providing explanations regarding the corresponding input features that are positively/ negatively affecting the decision . The procedure for significance/relevance calculation is as follows: From the model weights and architecture construct a graph with output nodes as roots and input nodes as the leaves. The propagation starts at root and proceeds in breadth-first manner to avoid re-processing of any node. The propagation completes when all the leaves(input nodes) have been assigned relevance. For the default mode, any loss of relevance during propagation is due to network bias. However, network bias is ignored for relevance computation in the contrastive mode. The relevance of a single sample represents local importance. For global importance, the relevance of each feature can be aggregated after normalization on the sample level.","title":"How does Arya-xAI work?"},{"location":"algo/#impact-on-pruning-and-model-result-assessment","text":"For model pruning, current explainable approaches offer limited evidence on node/layer level importance in final prediction. The limits range from type of data to network architecture. Arya-XAI uses a unique approach to figure out the importance of each node/layer on the final prediction. This allows a much deeper explainability of the complex black box models for data scientists/researchers, allowing them to gauge which features have the most impact on the model decision. Explanations can be generated at a local level as well as a global level. Global level explanations can be used to study the overall model trend, data usage and identify possible improvements. Local level explanations are important for granular control over data usage and unit level performance of the network. Local level explanations not only help in analyzing model outputs for individual samples, they also help in establishing internal trends in any feature with respect to the decision. This facilitates in building feature-level decision boundaries and flag any adverse predictions.","title":"IMPACT ON PRUNING AND MODEL RESULT ASSESSMENT"},{"location":"examples/","text":"#Example IMPLEMENTING ARYA-xAI IMAGE CLASSIFICATION ON MNIST DATA MNIST DATA (INPUT) We have used the MNIST character recognition dataset to demonstrate the Arya-xAI framework. The MNIST dataset of handwritten single digits between 0 and 9, consists of 60,000 small, square grayscale images with resolution 28\u00d728pixels. A custom architecture, which contains most of the commonly used components such as convolutions and lstms, is designed for this data.","title":"Example"},{"location":"examples/#implementing-arya-xai-image-classification-on-mnist-data","text":"","title":"IMPLEMENTING ARYA-xAI IMAGE CLASSIFICATION ON MNIST DATA"},{"location":"examples/#mnist-data-input","text":"We have used the MNIST character recognition dataset to demonstrate the Arya-xAI framework. The MNIST dataset of handwritten single digits between 0 and 9, consists of 60,000 small, square grayscale images with resolution 28\u00d728pixels. A custom architecture, which contains most of the commonly used components such as convolutions and lstms, is designed for this data.","title":"MNIST DATA (INPUT)"},{"location":"network_detail/","text":"NEURAL NETWORK USED","title":"Network Details"},{"location":"network_detail/#neural-network-used","text":"","title":"NEURAL NETWORK USED"},{"location":"use_the_api/","text":"Navigate to http://xai.arya.ai/ Sign up as a new user and login Click on the My Models option on the top right Upload the the model on the Add Model option Choose Model Type (saved model or h5 format) Add the downloadable URL of the model and submit","title":"Let's Get Started"}]}