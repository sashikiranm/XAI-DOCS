{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Arya XAI (Explainable-AI) At Arya.ai, we recently released a new framework - \u2018Arya-XAI\u2019 to simplify DLOps in production. Arya-XAI(short for Arya-Explainable AI) enhances the credibility of the predictions of your DL model by generating new and simple explanations (pertaining to the generation of these predictions) in real time as required by various stakeholders. This is the tutorial-first mode of operation for Arya-xAI and it also illustrates the capabilities of the framework. Current approaches to Explainable AI and their challenges Current approaches to explain black-box DL models are heavily reliant on specific data types and network components, both of which severely limit their applicability to a diverse range of use-cases and novel network architectures. This poses challenges to understand or explain true-to-model functioning(that takes into account the internal design of the model). However, models like SHAP, LIME, Integrated Gradients etc. use a permute-and-predict approach to explain the model functioning. While the approaches do offer approximate explanations of how a DL model works on the input to ultimately yield the output, unfortunately these are understandable only by an AI expert. Unlike the existing models such as SHAP and LIME which do not take the internal structure of a network into account to explain its working, the Arya-XAI framework decodes explanations by computing weightage of each feature together with the node-level weightages for a given neural network architecture, referred to as true-to-model feature and node-level weightages respectively. The framework not only improves reliability on DL models substantially, but also offers easy-to-understand reasons behind the outcome.","title":"Home"},{"location":"#welcome-to-arya-xai-explainable-ai","text":"At Arya.ai, we recently released a new framework - \u2018Arya-XAI\u2019 to simplify DLOps in production. Arya-XAI(short for Arya-Explainable AI) enhances the credibility of the predictions of your DL model by generating new and simple explanations (pertaining to the generation of these predictions) in real time as required by various stakeholders. This is the tutorial-first mode of operation for Arya-xAI and it also illustrates the capabilities of the framework.","title":"Welcome to Arya XAI (Explainable-AI)"},{"location":"#current-approaches-to-explainable-ai-and-their-challenges","text":"Current approaches to explain black-box DL models are heavily reliant on specific data types and network components, both of which severely limit their applicability to a diverse range of use-cases and novel network architectures. This poses challenges to understand or explain true-to-model functioning(that takes into account the internal design of the model). However, models like SHAP, LIME, Integrated Gradients etc. use a permute-and-predict approach to explain the model functioning. While the approaches do offer approximate explanations of how a DL model works on the input to ultimately yield the output, unfortunately these are understandable only by an AI expert. Unlike the existing models such as SHAP and LIME which do not take the internal structure of a network into account to explain its working, the Arya-XAI framework decodes explanations by computing weightage of each feature together with the node-level weightages for a given neural network architecture, referred to as true-to-model feature and node-level weightages respectively. The framework not only improves reliability on DL models substantially, but also offers easy-to-understand reasons behind the outcome.","title":"Current approaches to Explainable AI and their challenges"},{"location":"Layer_types/","text":"Layer Types Every neural network consists of multiple layers. Each layer has a variation of the following basic operation: y = \u03a6(Wx + b) where, \u03a6 = activation function \u200bW = weight matrix of the layer \u200bb = bias \u200bx = input \u200by = output Different activation layers perform a range of mathematical functions and are named as follows: Dense layer Convolution layer Pooling layer Recurrent layer (LSTM - Long Short Term Memory networks)","title":"Layer Types"},{"location":"Layer_types/#layer-types","text":"Every neural network consists of multiple layers. Each layer has a variation of the following basic operation: y = \u03a6(Wx + b) where, \u03a6 = activation function \u200bW = weight matrix of the layer \u200bb = bias \u200bx = input \u200by = output Different activation layers perform a range of mathematical functions and are named as follows: Dense layer Convolution layer Pooling layer Recurrent layer (LSTM - Long Short Term Memory networks)","title":"Layer Types"},{"location":"algo/","text":"How does Arya-xAI work? Arya XAI currently has two modes of operation known as default and contrastive mode which are demonstrated through the following use-cases respectively: Network Analysis: In this mode, there is a single,positive significance value that is propagated in proportion to the contribution of each unit. This can be used to prune the underutilized parts of the network and modify the saturated ones. This is also helpful in reducing or enhancing the input features. Decision Analysis: In this mode, there are dual significance values which can be either negative or positive depending on the relative contribution of any unit to the decision. This is helpful in providing explanations regarding the corresponding input features that are positively/ negatively affecting the decision . The procedure for significance/relevance calculation is as follows: From the model weights and architecture construct a graph with output nodes as roots and input nodes as the leaves. The propagation starts at root and proceeds in breadth-first manner to avoid re-processing of any node. The propagation completes when all the leaves(input nodes) have been assigned relevance. For the default mode, any loss of relevance during propagation is due to network bias. However, network bias is ignored for relevance computation in the contrastive mode. The relevance of a single sample represents local importance. For global importance, the relevance of each feature can be aggregated after normalization on the sample level. IMPACT ON PRUNING AND MODEL RESULT ASSESSMENT For model pruning, current explainable approaches offer limited evidence on node/layer level importance in final prediction. The limits range from type of data to network architecture. Arya-XAI uses a unique approach to figure out the importance of each node/layer on the final prediction. This allows a much deeper explainability of the complex black box models for data scientists/researchers, allowing them to gauge which features have the most impact on the model decision. Explanations can be generated at a local level as well as a global level. Global level explanations can be used to study the overall model trend, data usage and identify possible improvements. Local level explanations are important for granular control over data usage and unit level performance of the network. Local level explanations not only help in analyzing model outputs for individual samples, they also help in establishing internal trends in any feature with respect to the decision. This facilitates in building feature-level decision boundaries and flag any adverse predictions.","title":"How does Arya-xAI work?"},{"location":"algo/#how-does-arya-xai-work","text":"Arya XAI currently has two modes of operation known as default and contrastive mode which are demonstrated through the following use-cases respectively: Network Analysis: In this mode, there is a single,positive significance value that is propagated in proportion to the contribution of each unit. This can be used to prune the underutilized parts of the network and modify the saturated ones. This is also helpful in reducing or enhancing the input features. Decision Analysis: In this mode, there are dual significance values which can be either negative or positive depending on the relative contribution of any unit to the decision. This is helpful in providing explanations regarding the corresponding input features that are positively/ negatively affecting the decision . The procedure for significance/relevance calculation is as follows: From the model weights and architecture construct a graph with output nodes as roots and input nodes as the leaves. The propagation starts at root and proceeds in breadth-first manner to avoid re-processing of any node. The propagation completes when all the leaves(input nodes) have been assigned relevance. For the default mode, any loss of relevance during propagation is due to network bias. However, network bias is ignored for relevance computation in the contrastive mode. The relevance of a single sample represents local importance. For global importance, the relevance of each feature can be aggregated after normalization on the sample level.","title":"How does Arya-xAI work?"},{"location":"algo/#impact-on-pruning-and-model-result-assessment","text":"For model pruning, current explainable approaches offer limited evidence on node/layer level importance in final prediction. The limits range from type of data to network architecture. Arya-XAI uses a unique approach to figure out the importance of each node/layer on the final prediction. This allows a much deeper explainability of the complex black box models for data scientists/researchers, allowing them to gauge which features have the most impact on the model decision. Explanations can be generated at a local level as well as a global level. Global level explanations can be used to study the overall model trend, data usage and identify possible improvements. Local level explanations are important for granular control over data usage and unit level performance of the network. Local level explanations not only help in analyzing model outputs for individual samples, they also help in establishing internal trends in any feature with respect to the decision. This facilitates in building feature-level decision boundaries and flag any adverse predictions.","title":"IMPACT ON PRUNING AND MODEL RESULT ASSESSMENT"},{"location":"examples/","text":"MNIST DATA (INPUT) We have used the MNIST character recognition dataset to demonstrate the Arya-xAI framework. The MNIST dataset of handwritten single digits between 0 and 9, consists of 60,000 small, square grayscale images with resolution 28\u00d728pixels. A custom architecture, which contains most of the commonly used components such as convolutions and lstms, is designed for this data. NEURAL NETWORK USED INPUT NETWORK ARCHITECTURE OUTPUT NETWORK ARCHITECTURE from Arya-xAI OUTPUT Default Mode Contrastive Mode (Reference : BLUE - negative contrast , GREEN - positive contrast)","title":"Implementing Arya-xAI Image Classification on MNIST Data"},{"location":"examples/#mnist-data-input","text":"We have used the MNIST character recognition dataset to demonstrate the Arya-xAI framework. The MNIST dataset of handwritten single digits between 0 and 9, consists of 60,000 small, square grayscale images with resolution 28\u00d728pixels. A custom architecture, which contains most of the commonly used components such as convolutions and lstms, is designed for this data.","title":"MNIST DATA (INPUT)"},{"location":"examples/#neural-network-used","text":"INPUT NETWORK ARCHITECTURE OUTPUT NETWORK ARCHITECTURE from Arya-xAI","title":"NEURAL NETWORK USED"},{"location":"examples/#output","text":"","title":"OUTPUT"},{"location":"examples/#default-mode","text":"","title":"Default Mode"},{"location":"examples/#contrastive-mode","text":"(Reference : BLUE - negative contrast , GREEN - positive contrast)","title":"Contrastive Mode"},{"location":"use_the_api/","text":"HOW TO USE THE ARYA-xAI API? Navigate to http://xai.arya.ai/ Sign up as a new user and login Click on the My Models option on the top right Upload the the model on the Add Model option Choose Model Type (saved model or h5 format) Add the downloadable URL of the model and submit Once added successfully, the model will be listed as follows: \u200btoken number - 1634#######88 (alphanumeric string) Model URL - the-downloable-link \u200bModel Type - saved model or h5 format Launch Time - dd/mm/yyyy hh:mm:ss \u200bView API - link to view details \u200bDELETE - link to delete the added model API DETAILS Request Field Parameters: mode - either default or contrast token - alphanumeric string referring to the model ID is_multi_input - whether or not the model accepts multiple inputs(True or False) model_input - model input as a list or numpy array scaler - to scale the initial model weights (>0) predictions - the model predicted value (True or False flag, if True send network output in response) Response (either as a numpy array or a json compatible list) data field - weights of all input layers specified by layer-name as key-value pairs ( layer_name : list of weights ) if default mode - data field has just one entry per layer if contrast mode - for each layer there will be entries corresponding to the positive and negative contast network_output field - output corresponding to each output layer (empty if prediction flag is False)","title":"How to Use the API?"},{"location":"use_the_api/#api-details","text":"","title":"API DETAILS"},{"location":"use_the_api/#request-field-parameters","text":"mode - either default or contrast token - alphanumeric string referring to the model ID is_multi_input - whether or not the model accepts multiple inputs(True or False) model_input - model input as a list or numpy array scaler - to scale the initial model weights (>0) predictions - the model predicted value (True or False flag, if True send network output in response)","title":"Request Field Parameters:"},{"location":"use_the_api/#response","text":"(either as a numpy array or a json compatible list) data field - weights of all input layers specified by layer-name as key-value pairs ( layer_name : list of weights ) if default mode - data field has just one entry per layer if contrast mode - for each layer there will be entries corresponding to the positive and negative contast network_output field - output corresponding to each output layer (empty if prediction flag is False)","title":"Response"}]}